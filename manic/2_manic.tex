\section{MANIC Architecture}
\label{manic:manic}
\manic is a processor microarchitecture that implements the
vector-dataflow execution model to improve energy efficiency while
maintaining programmability and generality.
%
\manic's hardware/software interface is a recent revision of the RISC-V
ISA vector extension~\cite{riscv_2019}.
%
\manic adds a vector unit with a single lane to a simple, in-order scalar processor core.
%
The vector unit has a few simple additions to support vector-dataflow execution: instruction windowing hardware and a renaming mechanism together implement
forwarding between dependent instructions.
%
With no modifications to the ISA, \manic runs programs efficiently.  With a
minor ISA change, \manic further improves efficiency by conveying register kill
annotations; the microarchitecture uses these annotations to
kill registers instead of incurring the cost of writing them to the vector
register file. 

\subsection{Vector ISA}
\label{manic:manic:isa}
The software interface to \manic's vector execution engine is the RISC-V ISA
vector extension~\cite{riscv_2019} and RISC-V code\footnote{Specifically, RISC-V E extension, which uses 16 architectural registers.} will run efficiently on a \manic
system with only minor modifications to add {\tt vfence} instructions for synchronization and  memory consistency. 

A programmer may further optionally recompile their code using our custom \manic
compiler to use minor ISA changes that support code scheduling and vector
register kill annotations.  We emphasize that these compiler-based features do
not require programming changes, do not expose microarchitectural details, and
are optional to the effective use of \manic.%

\manic implements the RISC-V V vector extension. RISC-V V does not specify a
fixed number of vector registers, but its register name encoding includes five
bits for vector register names.  We implement 16 vector registers, requiring
four bits to name, and leaving a single bit in the register name unused.
We use the extra bit in a register's name to convey kill annotations from the
compiler to the microarchitecture.  If either of an instruction's input
registers has its high-order bit set, the encoded instruction indicates to
\manic that the register dies at the instruction.
%
To support code scheduling, \manic's optional compiler support runs the
dataflow code scheduling algorithm (described in \autoref{manic:design:schedule}).
%
After scheduling, the compiler analyzes definitions and uses of each register
and adds a kill annotation to a killed register's name in the instruction 
at which it dies. 

\subsection{Microarchitecture}
\label{manic:manic:uarch}
\manic's microarchitecture is split along the two phases of execution: Decode \& Rename and Execute.
% 
During the Decode \& Rename Phase, \manic buffers a window of decoded instructions (``Insn Buffer'') and identifies dataflow between them, renaming operands to point to the ``Forwarding Buffer'' as dataflow allows.
% 
Then during the Execute Phase, \manic cycles through the instruction buffer (``VIssue''), determines where the source of each instruction operand (``VGate''), executes the operation (``VExecute'' and ``VMemory''), and performs a write back if necessary (``VWriteback'').
%
\autoref{fig:manic:block} shows the two phases of execution as well as the different microarchitectural components of each.

\figMANICBlock

\subsubsection{Decode \& Rename}
Decode \& Rename is responsible for creating a window of
instructions to execute according to vector-dataflow.
%
The Decode \& Rename logic activates once per window of instructions, identifying,
preparing, and issuing for execution a window of dependent instructions over an entire vector of inputs.
%
% A key parameter is the length of the instruction buffer
% window, which we explain next.
%
The logic analyzes a short sequence of instructions that has the same
number of instructions as the instruction buffer can hold. 
%
Decode \& Rename identifies dataflow between instructions by comparing the names
of their input and output operands. 
%
If two instructions are dependent --- the output of one of the instructions is 
the input of another ---  \manic should forward the output value directly from
its producer to the input of the consumer, avoiding the register file.
\manic's rename logic implements forwarding by renaming the instructions' register operands 
to refer to a free location in \manic's forwarding
buffer, instead of to the register file. 
%
The Decode \& Rename logic records the renaming in \manic's renaming table, which is a
fixed-size, directly-indexed table, with one entry for each register that can
be renamed in a window of instructions.
%
After Decode \& Rename identifies dependent operations and performs renaming for the window, it dispatches the window of operations for execution.


\paragraph{Instruction buffer}
\manic uses its instruction buffer to store an decoded window of
instructions that have had their register operands renamed by the Decode \& Rename logic.
% 
Each entry of buffer tells the Execute phase where to read and write an operand.
% 
For input operands, the instruction buffer controls whether to fetch an operand from the
vector register file, from the Xdata buffer (data buffered from the scalar core like base address or stride), or from \manic's forwarding buffer (in the case of an
operand being forwarded between instructions in the window).
%
Likewise, for output operands, the instruction buffer controls whether to write
an output operand to the vector register file, to the forwarding buffer, or to both.

\paragraph{Limits to window size}
There are several classes of instructions that limit window size.
%
These include stores, permutations, and reductions.
%
Permutations and reductions require interactions between elements in a vector, which
creates a {\em horizontal} dependence between operations on different vector elements.
%
\manic does not support forwarding for such operations because of the complexity of
the dependence tracking that they introduce.  
% 
Instead, these operations execute one element at a time, ultimately writing to the vector register file. 

A store also ends the decoding and renaming of a window.  A store may write to a memory
location that a later operation loads from. Such a through-memory dependence is 
unknown until execution time.  Consequently, \manic conservatively assumes
that the address of any store may alias with the address of any load or store in the window (i.e., in a later vector element).
A store ends the construction of a window to avoid the need for dynamic memory disambiguation to
detect and avoid the effect of such aliasing.
% 
We evaluated adding a \emph{non-aliasing store} instruction that would allow \manic to forward past stores,
but this instruction improved energy-efficiency by less than $0.5\%$ in our applications.
% 
This is because store instructions often naturally close windows (e.g. a {\tt vfence} follows the store to ensure correctness).
% 
Thus, given the added programming complexity for minimum benefit, we conclude that such an instruction is unnecessary.
%

\paragraph{Xdata buffer}
Some instructions like vector loads and stores require extra information 
(e.g. base address and stride) available from the scalar register file when the instruction is decoded.
%
Due to the loosely coupled nature of \manic, this extra information must be buffered 
alongside the vector instruction.
%
Since not all vector instructions require values from the scalar register file, 
\manic includes a separate buffer, called the xdata buffer, to hold this extra
information.
%
Entries in the instruction buffer contain indices into the xdata buffer as needed.
%
During execution, \manic uses these indices to read information from the xdata buffer and execute accordingly.

\paragraph{Structural hazards}
There are two structural hazards that cause \manic to stop buffering additional
instructions, stall the scalar core, and start vector execution. 
%
The first hazard occurs when the instruction buffer is full and another vector instruction is waiting to be buffered.
%
The second hazard occurs when the xdata buffer is full and a decoded 
vector instruction requires a slot.
%
The prevalence of each hazard depends on the size of the buffers associated with each.
%
The first hazard is most common, while the second is rare.

\subsubsection{Execute}
The Execute Phase begins once a {\tt vfence} instruction is reached or there is a structural hazard.
% 
\manic has a five-stage execution pipeline consisting of: VIssue, VGate, VExecute, VMemory, and VWriteback.
% 
VIssue tracks execution progress and maintains a pointer into the instruction buffer, reads decoded instructions, and (only if necessary) initiates VRF reads;
VGate determines the source for each operand (the VRF, Xdata buffer, Forwarding buffer, or bypass paths) and steers operands to the multiplier or ALU;
VExecute computes the ALU and multiplier results;
VMemory issues loads and stores;
and VWriteback writes results to the Forwarding Buffer or VRF, as appropriate.

\paragraph{VIssue}
VIssue determines what the execution pipeline should execute next and initiates VRF reads if they are necessary (no dataflow identified during Decode \& Rename).
% 
It maintains an instruction pointer into the instruction buffer for the current instruction as well as counter representing the completed vector length.
% 
Together these track the progress of execution.
% 
Execution proceeds first vertically through the entire window.
% 
VIssue bumps the instruction pointer for each entry in the instruction buffer, reconfiguring the pipeline according to each instruction.
% 
Then execution proceeds horizontally; VIssue resets the instruction pointer to the top of the instruction buffer and increments the completed vector length counter.
% 
When the completed vector length counter matches the vector length of the computation and the instruction pointer is at the end of the instruction buffer, execution is finished.

\paragraph{VGate}
VGate chooses the source for each operand.
% 
Possible sources include the VRF, the Xdata buffer, bypass paths or the Forwarding buffer.
% 
VGate reduces switching activity in VExecute by steering operands to dedicated input registers for the ALU or multiplier to, e.g., prevent a VADD from toggling the multiplier.
%
This is important because, unlike conventional vector execution, the active instruction changes every cycle in \manic, increasing activity on control and data signals.

\paragraph{Forwarding buffer} 
The forwarding buffer stores intermediate values as \manic's execution unit forwards them to
dependent instructions in the instruction window. 
%
The buffer has a single read port, single write port, and an single entry (32b$\times$16) for each vector register.
%
It is simple (1r1w) and small (64B in total), which corresponds to a very low static power and access energy compared to the very 
high static power and access energy of the vector register file.
%
By accessing the forwarding buffer instead of accessing the vector register
file, an instruction with one or more forwarded operands consumes less energy
than one that executes without \manic. 

\paragraph{Efficient reductions}
RISC-V V contains {reduction} instructions like \texttt{vredsum v1 v2},
which adds up all elements of \texttt{v2} and writes the sum into the first element of \texttt{v1}.
%
% \manic has a register for reductions for accumulating relies on the forwarding buffer to avoid VRF accesses for reductions.
% 
\manic supports these operations efficiently without accessing the VRF by accumulating partial results in a single 32b reduction register.
% 
This is possible because windows close on reductions so there will only ever be a single reduction per window.
% , avoiding accessing the VRF.
% 
% Instead of writing partial results to the VRF,
% \manic has a single 32b reduction register for accumulating partial results.
% 
% allocates space in the forwarding buffer for partial accumulation.
% 
The Decode \& Rename logic recognizes a reduction, and remaps the second source operand and the destination to point to the reduction register.
% 
During the Execute phase, \manic will then use the partial result in the reduction register as one source for the reduction (e.g., sum)
and overwrite it with the new value as it is produced.
% 
This optimization re-purposes \manic's existing dataflow mechanisms
to save an entire vector-length of VRF reads and writes for reductions.

\subsection{Memory system}
\label{manic:manic:memory}
\manic's memory subsystem includes an instruction cache (icache) and a data cache (dcache).
%
This departs from the designs of many commercial microcontrollers 
in the ultra-low-power computing domain, which do
not have dcaches and have extremely small icaches on the order of 
64 bytes~\cite{msp430fr5994}.
%
However, we find that even small or moderately sized dcaches (512B) are effective in minimizing the number of accesses to main memory. 
%
We measured miss curves for the different application we consider; 
for each application there is an extreme drop-off in the number of misses for even 
small cache sizes,  and with a 512B cache the curves are basically flat.
%
Since the energy of an access to main memory dwarfs an access to the dcache,
the dcache offers a significant reduction in energy.

\paragraph{Caching and intermittence}
In the intermittent computing domain, improperly managed caches may
lead to memory corruption because dirty data may be lost when power fails.
%
As such, \manic assumes a hardware-software JIT-checkpointing mechanism
(like~\cite{hibernusplusplus, samoyed, quickrecall}) for protecting the caches
and any dirty data.
%
Checkpointing energy for cached data is virtually negligible because caches are
very small relative to the operating period. 
%

\subsection{Putting it together with an example}
We illustrate the operation of the Decode \& Rename logic, renaming table, instruction
buffer, and forwarding buffer with an example of \manic's operation, shown in
\autoref{fig:manic:vde:issue}. 
%
The figure starts with vector-aware assembly code that \manic transforms into
vector-dataflow operations by populating the renaming table and instruction
buffer with information about the dataflow.
%
Vector assembly instructions pass into \manic's microarchitectural mechanisms
as they decode and later execute.
%

\figMANICMANICa

\paragraph{Decoding instructions and renaming operands}
The figure shows a three-instruction program and illustrates how
the Decode \& Rename logic populates the instruction buffer and remaps registers for each
instruction.

\begin{itemize}
\item {\tt vload}:
The rename logic records the load in the instruction window and, since the instruction
is a vector load and requires a base address, also inserts the base address ({\tt \&a} forwarded from the scalar register file) into the xdata buffer.
% 
In addition, the logic writes an empty renaming entry to {\tt v0} in the renaming table along with the index of the instruction in the instruction buffer.
%
An empty renaming entry at execution time signifies a vector register write.
However, during Decode \& Rename, an empty entry may be filled by an instruction added to
the instruction window later during the same Decode \& Rename phase.
\item {\tt vmul}: The multiply instruction consumes two register operands that are not in the renaming table and, at execution time, will issue
two vector register file reads.
%
As with the load, the rename logic records the multiply's output register with 
an empty entry in the renaming table as well as the index of the multiply in the
instruction buffer.
\item {\tt vadd}:
The add's inputs are {\tt v0} and {\tt v1} with the kill annotation indicating
that the instruction kills register {\tt v0}.
%
The rename logic looks up each input operand in the renaming table and, finding 
both have valid entries, identifies this instruction as the target for forwarding.
%
The rename logic remaps {\tt v0} to refer to the first entry of the forwarding
buffer and {\tt v1} to the second position. 
%
The load instruction in the instruction buffer (found by the saved index in the renaming table) 
is updated and will store its result in {\tt F0} instead of {\tt v0}.
%
Similarly, the multiply instruction is also updated and will store its result in {\tt F1}, but since {\tt v1} is not killed, it will still be written-back to the register file. 
%
The add instruction then will fetch its input operands from {\tt F0}
and {\tt F1} instead of the vector register file.
%
The kill annotations associated with {\tt v3} and {\tt v0} follow the re-written
instructions into the instruction window, enabling their use during execution
to avoid register file writes.
\end{itemize}

\figMANICMANICb

\paragraph{Executing a window of instructions}
After Decode \& Rename, the window of instructions is ready to execute.
\autoref{fig:manic:vde:execute} shows (via the orange control-flow arcs) how \manic
executes the entire window vertically for a single vector element before moving
on to execute the entire window for the second vector element.
%
The blue dataflow arcs show how \manic forwards values between dependent
instructions using its forwarding buffer.  The green squares marked with ``F'' names
are forwarded values.
%
The figure also shows how \manic uses a kill annotation at runtime.
%
The registers with kill annotations ({\tt v0} and {\tt v3}) need not be written
to the vector register file when the window completes executing, sparing the
execution two vector register writes required by a typical vector execution. 

\subsection{Microarchitecture-agnostic dataflow scheduling}
\label{manic:design:schedule}
\manic's final feature is {\em microarchitecture-agnostic
dataflow scheduling}.
%
This feature is optional compiler support that
re-orders vector instructions to make dependent operations as close as possible to one another.  If dependent operations are closer together in an instruction
sequence, then it is more likely that they will appear together in one of
\manic's vector-dataflow windows.  By re-ordering operations to appear close
together in a window, \manic creates more opportunities to
forward values from a producer instruction to its consumer,
eliminating more vector register file accesses.

\manic's dataflow scheduler does not compromise programmability or generality.
The programmer need not understand the microarchitecture to reap the benefits
of the dataflow scheduler.  The dataflow scheduler minimizes the forwarding
distance between dependent instructions, rather than targeting a particular
window size.  While not always optimal for a given window size, this
microarchitec-ture-agnostic optimization prevents the compiler from being
brittle or dependent on the microarchitectural parameters of a
particular system. 

To minimize forwarding distance between dependent instructions, \manic's
dataflow code scheduler uses {\em sum kill distance}.  A vector register's
kill distance is the number of instructions between when an instruction defines
the register and when the value in the register is used for the last time
(i.e., the register dies).  The sum kill distance is the sum of all registers'
kill distances across the entire program. To remain agnostic to the window size
of particular \manic implementation, the code
scheduler minimizes the sum kill distance (which is equivalent to minimizing
average kill distance).  Sum kill distance is a proxy for the number of
register writes in a program because if a register does not die during a
window's execution, the system must write its value back to the register file.
%
When sequences of dependent instructions are closer together, their
intermediate values die more quickly, because registers need not remain live
waiting for unrelated instructions to execute.  A larger window accommodates
dependence chains that include longer kill distances.

We implement dataflow code scheduling using brute force (exhaustive) search
for small kernels containing fewer than 12 vector operations.  For larger
kernels (e.g., FFT), we implement dataflow code scheduling via simulated
annealing that randomly mutates instruction schedules, 
while preserving dependences, to produce a new valid schedule, accepting 
this new schedule with some probability.

\figMANICKill

\autoref{fig:manic:kill} shows that the microarchitecture-agnostic minimization of
the sum kill distance closely approximates a microarchitecture-specific
approach that optimizes for a particular window size.
%
The plot shows the number of register writes made by one iteration of the
kernel's inner loop for a given window size using code optimized by the two
different optimization criteria. 
%
The blue line shows the number of register writes of a \emph{microarchitecture-specific} schedule,
where window size is exposed to the compiler.  The red line shows the number of writes
for our \emph{microarchitecture-agnostic} schedule based on sum kill distance.
%
The two curves generally agree, suggesting that minimizing sum kill distance eliminates
register writes with similar efficacy as when window size is exposed explicitly to the compiler.
%
For the FFT kernel, the instruction window is broken by stores and permutations (\autoref{manic:manic:uarch}),
causing additional vector register file writes.
% 
This is a limitation of optimizing only for sum kill distance and could be fixed by taking into account these operations during optimization.
% that we plan to address in future work.
