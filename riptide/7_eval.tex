\section{Evaluation}
\label{riptide:eval}

\figRipTidePrimaryArchResults
\figRipTidePrimaryCompilerResults
\figRipTideFINResults
\figRipTideLoCResults

We evaluate \riptide to show that it is easy to program in a high-language,
uses 25\% less energy than the state of the art,
and improves performance by 17\% on average and up to 2.5$\times$.
Moreover, control flow in the NoC is essential for large
workloads and reduces energy by up to 2.25$\times$.

\subsection{Main results}

\paragraph{\riptide compiles high-level-language code to its fabric.} \riptide
compiles, schedules, and runs ten applications on its 6$\times$6 fabric.
% 
For all but {\tt fft}, \riptide offloads the entire benchmark onto the fabric, including
outer loops.
% 
For {\tt fft}, a 6$\times$6 fabric does not have enough arithmetic or multiplier PEs,
so we split {\tt fft} into two separate functions. 
% 
Further, \riptide maps and runs {\tt dfs}, which is {\em not possible} for
the vector and \snafu baselines (Xs in the figures).

\paragraph{\riptide saves energy.}
\autoref{fig:riptide:eval:energy} presents energy of the scalar, vector, 
\snafu, and ASICs normalized to \riptide.
% 
\riptide reduces energy by 6.6$\times$ vs. scalar, 3.1$\times$ vs. vector, and 25\% vs. \snafu.
%
\riptide uses less energy across the board.
% 
\autoref{fig:riptide:eval:energy} breaks energy into memory, scalar, and vector/CGRA.
% 
\riptide saves energy vs.\ scalar and vector because it does not fetch instructions,
re-uses its configuration across many inputs, and forwards operands 
directly from producers to consumers.
% 
\riptide uses less energy than \snafu by reducing scalar computation:  \riptide runs
outer loops on the fabric, but \snafu runs them on the scalar core.
% 
Avoiding scalar work also eliminates instruction-fetch (memory) energy. 

The only benchmark for which memory energy increases vs.\ \snafu is {\tt fft}.
% 
\snafu uses scratchpads in the fabric for {\tt fft}, which reduces main memory energy.
% 
Even without scratchpads, \riptide shows an overall energy reduction.
(\riptide could use scratchpads as well in future work.)

{\tt sconv}'s case shows how control-flow costs in \riptide move from scalar core to the
fabric (e.g., steer, carry).
% 
While \riptide eliminates scalar cost (e.g., fetches), it adds fabric energy (vs.\
\snafu) to support outer loops.
% 
Scalar execution is a small fraction of overall energy for {\tt sconv},
so \riptide provides no benefit on this benchmark.
%
This result further shows that \riptide's microarchitectural additions cost little energy.


\autoref{fig:riptide:eval:energy} also compares \riptide to hand-coded, fixed-function
ASICs for {\tt dmm}, {\tt sort}, and {\tt fft}.
% 
\riptide uses just 53\% more energy on average than the ASICs, while running
applications compiled directly from C. % with full programmability.
% 
\riptide compares especially favorably to {\tt dmm}, using just 32\% more energy.
% 
The data show that the cost of \riptide's programmability is low.

\paragraph{\riptide is fast.}
\autoref{fig:riptide:eval:perf} shows performance normalized to scalar.
%
\riptide is 6.2$\times$, 3.4$\times$, and 17\% faster than vector, scalar, and \snafu.
%% % 
%
\riptide achieves this performance from C code without hand-coded assembly.
% 
\riptide does especially well on {\tt bfs}, with a 2.5$\times$ speedup vs. \snafu. The benefit comes
from \riptide's ability to run even {\tt bfs}'s irregular outer loop on the fabric, whereas
% 
\snafu runs only inner loops on its fabric, causing a performance
bottleneck on the scalar core. % , running the outer loop on the scalar core.

\paragraph{\riptide is tiny and has extremely low power consumption.}
%
The complete \riptide system is approximately 0.5mm$^2$ and operates between
320\textmu W and 600\textmu W, with negligible leakage (<3\%) due to \riptide's high-threshold-voltage process.
% 
Overall, the complete system, including memory, achieves 141 MOPS/mW vs.\ 110 
MOPS/mW for \snafu's full system.

\subsection{Compiler characterization}
\riptide's compiler effectively optimizes dataflow graphs, reducing operation
counts by 26\% while enforcing memory ordering vs.\ an unoptimized DFG without
ordering.
% 
The compiler also reduces programmer effort: \riptide compiles from C with
no hand-coded assembly, requiring just 8.7 added LoC on average over the original
C (mostly for wrappers).

\paragraph{\riptide's compiler reduces operation counts.} Reducing operation count
is important because they consume PEs in \riptide's fabric.
%
\autoref{fig:riptide:eval:ops} shows operation counts by type with different optimizations applied.
% 
The first bar is an unoptimized DFG mapped to \riptide.
% 
This graph requires many PEs to map to hardware and may yield incorrect
results because it does not enforce memory ordering.
% 
The second bar adds streams, operator fusion, and redundant control flow
elimination, reducing operation count by 32.6\%.
% 
The third bar adds unoptimized memory ordering, which {\em increases} operations counts by 85.3\% to ensure correctness.
% 
Mapping this graph to hardware is challenging due to its size.
% 
The fourth bar applies \riptide's ordering optimizations (\autoref{sec:compiler}), reducing operation count (vs. unoptimized ordering) by 27.7\%.
% 
The fifth bar adds programmer-inserted ({\tt restrict}) annotations on pointers
to better inform LLVM's alias analysis, reducing operation count by 18.2\%.
% 
The last bar removes control-flow operations that map to \riptide's NoC, reducing
the number of operations on PEs by 37.5\% and demonstrating the benefit of
\riptide's control flow in the NoC.
% 

\paragraph{\riptide reduces programmer effort.}
\autoref{fig:riptide:eval:loc} counts code additions, including lines of code (LoC) in C, assembly, and {\tt restrict} annotations.  
%
\riptide has no hand-written assembly, compiling directly from C, while  32\% and
27\% of the LoC for the vector and \snafu baseline are hand-written assembly.
% 
On average, vector adds 17 LoC vs. scalar, \snafu adds 21 LoC vs. scalar, and
\riptide adds just 8.7 lines.
% 
Annotations in \riptide represent a small fraction of the overall LoC, just 11.2\%
and, on average, the programmer adds 4.5 annotations per benchmark.

\subsection{CF in the NoC saves energy \& area}
\autoref{fig:riptide:eval:fin} quantifies the benefits of implementing control flow in the NoC (CFiN).
% 
From left to right, the plot shows base energy on \riptide with CFiN,
the same fabric with every control-flow operation on a PE,
an ``All PEs'' larger fabric with all CF operations mapped to PEs,
and a ``Fused'' fabric in which each PE supports one fused CF operation.
% 
\riptide uses the least energy: 45\% less than No CFiN, 42\% less than All PEs, and 29\% less than Fused.
% 
\riptide's benefit stems from CFiN avoiding the overhead of a full PE.
%
Other configurations also have unique problems.
% 
No-CFiN is possible only for {\tt dmv} and {\tt smv}, which are small enough to map to the
same \riptide fabric; other workloads have too many control-flow operations to map.
% 
The All PEs and Fused configurations add many control-flow PEs, wasting energy and area.
% 
In contrast, \riptide is 22\% and 17\% smaller than All PEs and Fused, respectively.
